{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import random\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "RUNNING = True\n",
    "threadLimiter = threading.BoundedSemaphore(6)\n",
    "resultLock = threading.Lock()\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "RAM_LIST = list(range(128, 3072 ,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_type_list(workflow_file_path):\n",
    "    with open(workflow_file_path) as result_json:\n",
    "        data = json.load(result_json)\n",
    "    task_type_input_files_map = {}\n",
    "    for process in data['processes']:\n",
    "        if process['name'] not in task_type_input_files_map:\n",
    "            task_type_input_files_map[process['name']] = []\n",
    "        for in_file in process['ins']:\n",
    "            if data['signals'][in_file]['name'] not in task_type_input_files_map[process['name']]:\n",
    "                task_type_input_files_map[process['name']].append(data['signals'][in_file]['name'])\n",
    "\n",
    "    return task_type_input_files_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_file_from_to_bucket(copy_source, copy_destination):\n",
    "    bucket = s3.Bucket('cegielskir')\n",
    "    bucket.copy(copy_source, copy_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_execution_result_to_json(task_id, result_dict, executionResultLock):\n",
    "    executionResultLock.acquire()\n",
    "    with open('./execution_data.json') as result_json:\n",
    "        data = json.load(result_json)\n",
    "    if 'montage_0.35' not in data:\n",
    "        data['montage_0.35'] = []\n",
    "    new_recort = {}\n",
    "    \n",
    "    new_recort['task_id'] = task_id\n",
    "    for result_key in result_dict.keys():\n",
    "        new_recort[result_key] = result_dict[result_key]\n",
    "    \n",
    "    data['montage_0.35'].append(new_recort)\n",
    "    with open('./execution_data.json', 'w+') as result_json:\n",
    "        json.dump(data, result_json, indent=4)\n",
    "    executionResultLock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_workflow_task(config, ins, outs, ram, s3_path):\n",
    "    options = {\n",
    "        \"bucket\": \"cegielskir\",\n",
    "        \"prefix\": s3_path\n",
    "    }\n",
    "    os.environ['FUNCTION_TYPE'] = str(ram)\n",
    "    ins_arg = json.dumps(ins)\n",
    "    outs_arg = json.dumps(outs)\n",
    "    config_arg = json.dumps(config)\n",
    "    options_arg = json.dumps(options)\n",
    "    result = !node awsLambdaCommand.js {\"'\" + ins_arg + \"'\"} {\"'\" + outs_arg + \"'\"} {\"'\" + config_arg + \"'\"} {\"'\" + options_arg + \"'\"}\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_task(filename, foldername):\n",
    "    with open(foldername + filename) as single_workflow:\n",
    "        data = json.load(single_workflow)\n",
    "    task_name = data['processes'][0]['name']\n",
    "    process = data['processes'][0]\n",
    "    config = process['config']\n",
    "    ins = [ data['signals'][i] for i in process['ins'] ]\n",
    "    outs = [ data['signals'][i] for i in process['outs'] ]\n",
    "    run_and_save_results(config, ins, outs, ram, filename.split('_')[0], filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_save_results(config, ins, outs, ram, task_core,task_name):\n",
    "    print(\"Starting \" + str(task_name) + \" with ram \" + str(ram) + \"   core - \" + str(task_core))\n",
    "    result = execute_workflow_task(config, ins, outs, ram, 'data-collection/montage-0_25/' + task_core)\n",
    "    save_result(result, './montage-0.25-raw-results.json', str(ram), task_name)\n",
    "    threadLimiter.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(result, filename,ram, task_id):\n",
    "    resultLock.acquire()\n",
    "    with open(filename) as result_json:\n",
    "        data = json.load(result_json)\n",
    "    if ram not in data:\n",
    "        data[ram] = []\n",
    "    result_dict = {}\n",
    "    result_dict['task_id'] = task_id\n",
    "    result_dict['result'] = str(result)\n",
    "    data[ram].append(result_dict)\n",
    "    \n",
    "    with open(filename, 'w') as result_json:\n",
    "        data = json.dump(data, result_json, indent=4)\n",
    "    resultLock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_executable_files(exec_folder):\n",
    "    for exe_file in s3.Bucket('cegielskir').objects.filter(Prefix=exec_folder):\n",
    "        copy_source = {\n",
    "            'Bucket': 'cegielskir',\n",
    "            'Key': exe_file\n",
    "        }\n",
    "        \n",
    "        print(exe_file.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "montageV2_6-compiles/mAdd\n",
      "montageV2_6-compiles/mBackground\n",
      "montageV2_6-compiles/mBgModel\n",
      "montageV2_6-compiles/mConcatFit\n",
      "montageV2_6-compiles/mDiff\n",
      "montageV2_6-compiles/mDiffFit\n",
      "montageV2_6-compiles/mFitplane\n",
      "montageV2_6-compiles/mImgtbl\n",
      "montageV2_6-compiles/mProject\n",
      "montageV2_6-compiles/mViewer\n"
     ]
    }
   ],
   "source": [
    "path = 'montageV2_6-compiles/'\n",
    "copy_executable_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### TO BE CHANGED ###########################\n",
    "\n",
    "\n",
    "source_path = 'dc-start-montage-0_15/'\n",
    "folder_with_workflow_parts = 'montage-0_15/'\n",
    "workflow_file = './dc-workflow-0.15.json'\n",
    "\n",
    "###################### END TO BE CHANGED ####################### \n",
    "\n",
    "task_in_file_map = get_task_type_list(workflow_file)\n",
    "\n",
    "\n",
    "for task_type in task_in_file_map:\n",
    "    for exe_file in s3.Bucket('cegielskir').objects.filter(Prefix=exec_folder):\n",
    "        copy_exec_source = {\n",
    "            'Bucket': 'cegielskir',\n",
    "            'Key': exe_file\n",
    "        }\n",
    "        \n",
    "        copy_file_from_to_bucket(copy_exec_source, 'data-collection/' + folder_with_workflow_parts +task_type + '/')\n",
    "    \n",
    "#     for in_file in task_in_file_map[task_type]:\n",
    "#         copy_source = {\n",
    "#             'Bucket': 'cegielskir',\n",
    "#             'Key': source_path + in_file\n",
    "#         }\n",
    "        \n",
    "#         copy_file_from_to_bucket(copy_source, 'data-collection/' + folder_with_workflow_parts +task_type + '/' + in_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mProject', 'mDiffFit', 'mConcatFit', 'mBgModel', 'mBackground', 'mImgtbl', 'mAdd', 'mViewer'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for task_task_in_file_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('./' + folder_with_workflow_parts)\n",
    "#files.reverse()\n",
    "it = 1\n",
    "while True:\n",
    "    print(\"================================== NEW LOOP ====================================\")\n",
    "    if RUNNING:\n",
    "        for file in files:\n",
    "            for ram in RAM_LIST:\n",
    "                task_core = file.split('_')[0]\n",
    "                with open('./' + folder_with_workflow_parts + file) as single_workflow:\n",
    "                    data = json.load(single_workflow)\n",
    "                task_name = data['processes'][0]['name']\n",
    "                process = data['processes'][0]\n",
    "                config = process['config']\n",
    "                ins = [ data['signals'][i] for i in process['ins'] ]\n",
    "                outs = [ data['signals'][i] for i in process['outs'] ]\n",
    "                threadLimiter.acquire()\n",
    "                print(\"Iteration: \" + str(it))\n",
    "                threading.Thread(target=run_and_save_results, args=(config, ins, outs, ram, task_core,file)).start()\n",
    "                it += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
